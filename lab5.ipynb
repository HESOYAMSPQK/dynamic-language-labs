{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5\n",
    "### Задание 1\n",
    "Провести классификацию найденного датасета, методами решающего дерева и случайного леса . В формате Markdown написать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.\n",
    "\n",
    "### Выполнение работы:\n",
    "### Шаг 1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./base_v3.csv\")\n",
    "\n",
    "y = df[\"is_fraud\"]\n",
    "X = df.drop(\"is_fraud\", axis=1)\n",
    "\n",
    "# Разделение на тренировочные и тестовые данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод решающих деревьев\n",
    "Метод решающих деревьев (Decision Trees) представляет собой модель машинного обучения, которая используется для задач как классификации, так и регрессии. Он строит дерево решений путем разбиения данных на подмножества с учетом определенных условий по признакам. Каждый узел в дереве представляет собой тест на признаке, каждая ветвь - результат этого теста, а каждый лист - прогноз.\n",
    "\n",
    "Гиперпараметры решающего дерева:\n",
    "max_depth (максимальная глубина дерева):\n",
    "\n",
    "Описание: Максимальная глубина дерева. Управляет тем, насколько глубоко дерево может разветвляться.\n",
    "Возможные значения: Любое целое положительное число или None (без ограничения глубины).\n",
    "min_samples_split (минимальное количество образцов для разделения узла):\n",
    "\n",
    "Описание: Минимальное количество образцов, необходимых для разделения внутреннего узла. Большие значения помогают предотвратить переобучение.\n",
    "Возможные значения: Любое целое положительное число.\n",
    "min_samples_leaf (минимальное количество образцов в листе):\n",
    "\n",
    "Описание: Минимальное количество образцов, необходимых для нахождения в листе. Большие значения помогают предотвратить переобучение.\n",
    "Возможные значения: Любое целое положительное число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_tree = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Создание модели решающего дерева\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Поиск лучших параметров для решающего дерева\n",
    "grid_search_tree = GridSearchCV(decision_tree, param_grid_tree, refit=True, cv=5,n_jobs=-1)\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры для решающего дерева\n",
    "best_params_tree = grid_search_tree.best_params_\n",
    "best_score_tree = grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод резулютатов обучения методом решающих деревьев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для решающего дерева: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Точность решающего дерева на тестовом наборе: 0.9745833333333334\n",
      "\n",
      "Отчет по классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2038\n",
      "           1       0.92      0.91      0.92       362\n",
      "\n",
      "    accuracy                           0.97      2400\n",
      "   macro avg       0.95      0.95      0.95      2400\n",
      "weighted avg       0.97      0.97      0.97      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_tree = DecisionTreeClassifier(**best_params_tree)\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "accuracy_tree = best_tree.score(X_test, y_test)\n",
    "print(\"Лучшие параметры для решающего дерева:\", best_params_tree)\n",
    "print(\"Точность решающего дерева на тестовом наборе:\", accuracy_tree)\n",
    "\n",
    "predictions = best_tree.predict(X_test)\n",
    "\n",
    "# Отчет по классификации\n",
    "print(\"\\nОтчет по классификации:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод случайного леса\n",
    "Метод случайного леса (Random Forest) является ансамблевым методом, который строит несколько деревьев решений во время обучения и объединяет их для получения более точных и стабильных прогнозов. Он использует технику \"бутстрапа\" для случайного выбора подмножества данных для обучения каждого дерева и также случайно выбирает подмножество признаков при каждом разделении узла.\n",
    "\n",
    "### Гиперпараметры случайного леса:\n",
    "\n",
    "### n_estimators (количество деревьев):\n",
    "\n",
    "Описание: Количество деревьев в лесу.\n",
    "Возможные значения: Любое целое положительное число.\n",
    "\n",
    "### max_depth (максимальная глубина деревьев):\n",
    "\n",
    "Описание: Максимальная глубина каждого дерева в лесу.\n",
    "Возможные значения: Любое целое положительное число или None (без ограничения глубины).\n",
    "min_samples_split (минимальное количество образцов для разделения узла):\n",
    "\n",
    "Описание: Минимальное количество образцов, необходимых для разделения внутреннего узла. Большие значения помогают предотвратить переобучение.\n",
    "Возможные значения: Любое целое положительное число.\n",
    "\n",
    "### min_samples_leaf (минимальное количество образцов в листе):\n",
    "\n",
    "Описание: Минимальное количество образцов, необходимых для нахождения в листе. Большие значения помогают предотвратить переобучение.\n",
    "Возможные значения: Любое целое положительное число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение параметров для случайного леса\n",
    "# Указал маленькие значения для ускорения обучения\n",
    "param_grid_forest = {\n",
    "    'n_estimators': range(2, 10),\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Создание модели случайного леса\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Поиск лучших параметров для случайного леса\n",
    "grid_search_forest = GridSearchCV(random_forest, param_grid_forest, refit=True, cv=5,n_jobs=-1)\n",
    "grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры для случайного леса\n",
    "best_params_forest = grid_search_forest.best_params_\n",
    "best_score_forest = grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты обучения с помощью метода случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для случайного леса: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9}\n",
      "Точность случайного леса на тестовом наборе: 0.96\n",
      "\n",
      "Отчет по классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2038\n",
      "           1       0.91      0.82      0.86       362\n",
      "\n",
      "    accuracy                           0.96      2400\n",
      "   macro avg       0.94      0.90      0.92      2400\n",
      "weighted avg       0.96      0.96      0.96      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_forest = RandomForestClassifier(**best_params_forest)\n",
    "best_forest.fit(X_train, y_train)\n",
    "\n",
    "accuracy_forest = best_forest.score(X_test, y_test)\n",
    "print(\"Лучшие параметры для случайного леса:\", best_params_forest)\n",
    "print(\"Точность случайного леса на тестовом наборе:\", accuracy_forest)\n",
    "\n",
    "predictions = best_forest.predict(X_test)\n",
    "\n",
    "# Отчет по классификации\n",
    "print(\"\\nОтчет по классификации:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
